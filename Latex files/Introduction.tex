Snake robots are hyper-redundant mobile manipulators which move by slithering over the ground. Whereas GOAT (Gearless Omni-directional Acceleration-vectoring Topology) leg is a jumping monopod robot, that executes jumping gait to move around. Although these 2 robots has completely different topologies, both robot are highly dynamic and hence constitutes a difficult platform to implement localization and mapping algorithms especially visual SLAM. Due to this reason, no attempts were made in this making these 2 robots autonomous and all the motion executed via tele-operation. Furthermore, the planar SEA (Series Elastic Actuator) snake uses pegs/stones to push itself forward. As the camera is mounted on head of the snake robot(as seen in attached Fig.  \ref{fig:snake}), therefore these pegs/stones cause occlusions, which again make the task of mapping and localizing challenging. Another challenge with the snake robot is that the head stays very close to the ground during its motion which causes the horizon to be very high in the image and thus a significant part of the image space is occupied with the ground, which generally has a uniform texture. 

In this work, we evaluate the performance of ORB and LSD SLAM on these highly dynamic and suggest ways to improve their performance in such kind of systems. We start by using benchmark implementation of ORB and LSD on available datasets. This is just to test the successful installation of the implementations on our system. The results for these trials is not presented in the paper. We further evaluate the performance on video collected from a hand-held play station eye camera. Finally, we evaluate their performance on a dataset collected from a camera mounted on the snake robot and GOAT Leg robot. We compare the results from ORB and LSD SLAM with ground-truth values obtained from the Motion-Capture system (OptiTrack).
